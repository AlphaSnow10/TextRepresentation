{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdGK-oL2bS5B"
      },
      "source": [
        "#BOW(Bag of words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q68JmMh1bWqm"
      },
      "outputs": [],
      "source": [
        "paragraph =  \"\"\"I have three visions for India. In 3000 years of our history, people from all over\n",
        "               the world have come and invaded us, captured our lands, conquered our minds.\n",
        "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
        "               the French, the Dutch, all of them came and looted us, took over what was ours.\n",
        "               Yet we have not done this to any other nation. We have not conquered anyone.\n",
        "               We have not grabbed their land, their culture,\n",
        "               their history and tried to enforce our way of life on them.\n",
        "               Why? Because we respect the freedom of others.That is why my\n",
        "               first vision is that of freedom. I believe that India got its first vision of\n",
        "               this in 1857, when we started the War of Independence. It is this freedom that\n",
        "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
        "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
        "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
        "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
        "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
        "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
        "               I have a third vision. India must stand up to the world. Because I believe that unless India\n",
        "               stands up to the world, no one will respect us. Only strength respects strength. We must be\n",
        "               strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
        "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of\n",
        "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
        "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n",
        "               I see four milestones in my career\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOVMFl6ebjbZ",
        "outputId": "43165c11-8f1c-4faf-fe4f-d9fe7c11be5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWA7o_b1DYXg",
        "outputId": "40d34b78-33a3-4132-e28a-7bf417322709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['three vision india',\n",
              " 'year history people world come invaded u captured land conquered mind',\n",
              " 'alexander onwards greek turk mogul portuguese british french dutch came looted u took',\n",
              " 'yet done nation',\n",
              " 'conquered anyone',\n",
              " 'grabbed land culture history tried enforce way life',\n",
              " '',\n",
              " 'respect freedom others first vision freedom',\n",
              " 'believe india got first vision started war independence',\n",
              " 'freedom must protect nurture build',\n",
              " 'free one respect u',\n",
              " 'second vision india development',\n",
              " 'fifty year developing nation',\n",
              " 'time see developed nation',\n",
              " 'among top nation world term gdp',\n",
              " 'percent growth rate area',\n",
              " 'poverty level falling',\n",
              " 'achievement globally recognised today',\n",
              " 'yet lack self confidence see developed nation self reliant self assured',\n",
              " 'incorrect',\n",
              " 'third vision',\n",
              " 'india must stand world',\n",
              " 'believe unless india stand world one respect u',\n",
              " 'strength respect strength',\n",
              " 'must strong military power also economic power',\n",
              " 'must go hand hand',\n",
              " 'good fortune worked three great mind',\n",
              " 'dr vikram sarabhai dept',\n",
              " 'space professor satish dhawan succeeded dr brahm prakash father nuclear material',\n",
              " 'lucky worked three closely consider great opportunity life',\n",
              " 'see four milestone career']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cleaning the texts\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "lemitizer=WordNetLemmatizer()\n",
        "\n",
        "sentences = nltk.sent_tokenize(paragraph) #split the paragraph to individual sentences based on spaces.\n",
        "\n",
        "corpus = []\n",
        "\n",
        "for i in range(len(sentences)): ##loop for each sentences individually\n",
        "\n",
        "    review = re.sub('[^a-zA-Z]', ' ', sentences[i]) #replace any thing othwerwise characters with space\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    #review = [stemmer.stem(word) for word in review if not word in set(stopwords.words('english'))] #bad result\n",
        "    review = [lemitizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "print(len(corpus))\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCbCtVJQfcDu",
        "outputId": "359c900e-4b74-4833-dfb3-3a59dbe183d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<31x114 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 155 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Creating the Bag of Words model\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# cv = CountVectorizer()\n",
        "# x = cv.fit_transform(corpus)\n",
        "# x\n",
        "\n",
        "# #but x is still in sparse matrix shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQTpcEwGHZi4",
        "outputId": "90636abd-776a-4376-a1c4-112016c8f42a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(31, 114)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 1, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating the Bag of Words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "x = cv.fit_transform(corpus).toarray()\n",
        "print(x.shape)\n",
        "x\n",
        "#so we have 114 unique words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA0knvJadaIx"
      },
      "source": [
        "#N-GRAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxU5AJljkEis"
      },
      "source": [
        "##UNi-GRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9490468a",
        "outputId": "24e4c36f-7101-493f-cd34-ccbb9696290e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'thor': 5, 'hathodawala': 1, 'is': 2, 'looking': 4, 'for': 0, 'job': 3}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "v = CountVectorizer()\n",
        "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
        "v.vocabulary_\n",
        "\n",
        "# give each word individually and it's index as a column\n",
        "# by default(one gram)\n",
        "# using fit function not fit_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a2697fc",
        "outputId": "c2e00e31-0120-418c-86e9-0b2ab84d1c10",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'thor': 5, 'hathodawala': 1, 'is': 2, 'looking': 4, 'for': 0, 'job': 3}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v = CountVectorizer(ngram_range=(1,1))\n",
        "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
        "v.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fja1Hz8xkLCf"
      },
      "source": [
        "##BI-GRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "132a19d8",
        "outputId": "0e85a3c0-4921-4558-c283-68a1799d54f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'thor': 9,\n",
              " 'hathodawala': 2,\n",
              " 'is': 4,\n",
              " 'looking': 7,\n",
              " 'for': 0,\n",
              " 'job': 6,\n",
              " 'thor hathodawala': 10,\n",
              " 'hathodawala is': 3,\n",
              " 'is looking': 5,\n",
              " 'looking for': 8,\n",
              " 'for job': 1}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v = CountVectorizer(ngram_range=(1,2))\n",
        "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
        "v.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3b3d05f",
        "outputId": "51f92740-a5bb-461c-e88e-7703edf6001e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'thor': 12,\n",
              " 'hathodawala': 2,\n",
              " 'is': 5,\n",
              " 'looking': 9,\n",
              " 'for': 0,\n",
              " 'job': 8,\n",
              " 'thor hathodawala': 13,\n",
              " 'hathodawala is': 3,\n",
              " 'is looking': 6,\n",
              " 'looking for': 10,\n",
              " 'for job': 1,\n",
              " 'thor hathodawala is': 14,\n",
              " 'hathodawala is looking': 4,\n",
              " 'is looking for': 7,\n",
              " 'looking for job': 11}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v = CountVectorizer(ngram_range=(1,3))\n",
        "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
        "v.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT_sLD4lkvTY"
      },
      "source": [
        "##Task :\n",
        "\n",
        "1- remove stop words\n",
        "\n",
        "2- lemmatize the text\n",
        "\n",
        "3- apply n-gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2ca4ead"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"Thor ate pizza\",\n",
        "    \"Loki is tall\",\n",
        "    \"Loki is eating pizza\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8af5e103"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# load english language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess(text):\n",
        "    # remove stop words and lemmatize the text\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        filtered_tokens.append(token.lemma_)\n",
        "\n",
        "    return \" \".join(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "99c61291",
        "outputId": "06802b7e-8f3b-4350-ecaa-a26076b6e25b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thor eat pizza'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess(\"Thor ate pizza\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "a4b3eb32",
        "outputId": "039e25ea-075c-4e1a-983e-202156585e5a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Loki eat pizza'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess(\"Loki is eating pizza\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b315340d",
        "outputId": "1da2dbee-e124-4e3f-c78e-9ca84450b6cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thor eat pizza', 'Loki tall', 'Loki eat pizza']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_processed = [\n",
        "    preprocess(text) for text in corpus\n",
        "]\n",
        "corpus_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cfed6e3",
        "outputId": "f6deeaec-93e0-4e2f-b6d7-8be9cfe69ee8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'thor': 7,\n",
              " 'eat': 0,\n",
              " 'pizza': 5,\n",
              " 'thor eat': 8,\n",
              " 'eat pizza': 1,\n",
              " 'loki': 2,\n",
              " 'tall': 6,\n",
              " 'loki tall': 4,\n",
              " 'loki eat': 3}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v = CountVectorizer(ngram_range=(1,2))\n",
        "v.fit(corpus_processed)\n",
        "v.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be1e8368",
        "outputId": "e9334d30-8547-4140-be36-d709cfb12205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 0, 1, 0, 1, 1]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit >>>> take all the documents.\n",
        "# transform  >>> take sentence that you want to encode it.\n",
        "v.transform([\"Thor eat pizza\"]).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5a9ac22",
        "outputId": "80d9c4ac-3134-42a5-af0a-2e6acbc46d14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 0, 1, 0, 0, 0]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.transform([\"Hulk eat pizza\"]).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbmAW3Mo2LDh"
      },
      "source": [
        "#TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDoJsrAi2bVv"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK55auFW2cdG"
      },
      "outputs": [],
      "source": [
        "# Example documents\n",
        "docs = [\n",
        "  \"The quick brown fox jumps over the lazy dog.\",\n",
        "  \"A stitch in time saves nine.\",\n",
        "  \"The early bird catches the worm.\",\n",
        "  \"Actions speak louder than words.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2JWdu6V2OaI",
        "outputId": "a8a6ceeb-7c1f-4dc5-adbb-4c19d33135e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.32467583 0.         0.32467583 0.\n",
            "  0.32467583 0.         0.32467583 0.32467583 0.         0.\n",
            "  0.32467583 0.32467583 0.         0.         0.         0.\n",
            "  0.5119563  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.4472136  0.         0.         0.         0.4472136\n",
            "  0.         0.         0.4472136  0.         0.4472136  0.\n",
            "  0.         0.4472136  0.         0.        ]\n",
            " [0.         0.39264414 0.         0.39264414 0.         0.39264414\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.6191303  0.         0.         0.39264414]\n",
            " [0.4472136  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.4472136  0.\n",
            "  0.         0.         0.         0.4472136  0.         0.4472136\n",
            "  0.         0.         0.4472136  0.        ]]\n"
          ]
        }
      ],
      "source": [
        "# Create a TF-IDF vectorizer instance\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the documents\n",
        "tfidf.fit(docs)\n",
        "\n",
        "# Transform the documents into a TF-IDF matrix\n",
        "tfidf_matrix = tfidf.transform(docs)\n",
        "print(tfidf_matrix.toarray())\n",
        "\n",
        "# YOU CAN MAKE IT IN ONE LINE using fit_transform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atTQhcad5ltL"
      },
      "source": [
        "When sklearn.__version__ <= 0.24.x use following method\n",
        "\n",
        "get_feature_names()\n",
        "\n",
        "\n",
        "When sklearn.__version__ >= 1.0.x use following method\n",
        "\n",
        "get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9x3Xhgx4p4V",
        "outputId": "bec93819-f7e9-4985-fa85-7344155c4285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    actions      bird     brown   catches       dog     early       fox  \\\n",
            "0  0.000000  0.000000  0.324676  0.000000  0.324676  0.000000  0.324676   \n",
            "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "2  0.000000  0.392644  0.000000  0.392644  0.000000  0.392644  0.000000   \n",
            "3  0.447214  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "         in     jumps      lazy  ...      over     quick     saves     speak  \\\n",
            "0  0.000000  0.324676  0.324676  ...  0.324676  0.324676  0.000000  0.000000   \n",
            "1  0.447214  0.000000  0.000000  ...  0.000000  0.000000  0.447214  0.000000   \n",
            "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.447214   \n",
            "\n",
            "     stitch      than       the      time     words      worm  \n",
            "0  0.000000  0.000000  0.511956  0.000000  0.000000  0.000000  \n",
            "1  0.447214  0.000000  0.000000  0.447214  0.000000  0.000000  \n",
            "2  0.000000  0.000000  0.619130  0.000000  0.000000  0.392644  \n",
            "3  0.000000  0.447214  0.000000  0.000000  0.447214  0.000000  \n",
            "\n",
            "[4 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert the matrix to a pandas dataframe\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Display the dataframe\n",
        "print(df_tfidf)\n",
        "\n",
        "\n",
        "# will make every unique word as a feature, so because i have 22 columns.\n",
        "# noticed, the most frequency word is the least value of TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojS4YjMvFJqJ"
      },
      "source": [
        "## the numbers of uniques words(min_df)\n",
        "\n",
        "1- min_df>>>>>>> will control the numbers of words which will be appeared based on numbers of frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS9UECmk42NK",
        "outputId": "ca41ee10-955e-41ca-c841-a57e16aafa9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['brown' 'cat' 'dog' 'fox' 'lazy' 'quick' 'the']\n",
            "[[0.4804584  0.         0.         0.63174505 0.         0.4804584\n",
            "  0.37311881]\n",
            " [0.         0.         0.65249088 0.         0.65249088 0.\n",
            "  0.38537163]\n",
            " [0.4804584  0.63174505 0.         0.         0.         0.4804584\n",
            "  0.37311881]]\n"
          ]
        }
      ],
      "source": [
        "#the default of min_df is one\n",
        "doc1 = \"the quick brown fox\"\n",
        "doc2 = \"the lazy dog\"\n",
        "doc3 = \"the quick brown cat\"\n",
        "\n",
        "cv = TfidfVectorizer()\n",
        "X = cv.fit_transform([doc1, doc2, doc3])\n",
        "print(cv.get_feature_names_out())  # ['brown', 'cat', 'dog', 'fox', 'lazy', 'quick', 'the']\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTGkscNvE4DL",
        "outputId": "dd4dc39c-069a-4fe6-bd75-d2cc60f2b537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['brown' 'quick' 'the']\n",
            "[[0.61980538 0.61980538 0.48133417]\n",
            " [0.         0.         1.        ]\n",
            " [0.61980538 0.61980538 0.48133417]]\n"
          ]
        }
      ],
      "source": [
        "cv = TfidfVectorizer(min_df=2)\n",
        "X = cv.fit_transform([doc1, doc2, doc3])\n",
        "print(cv.get_feature_names_out())  # ['brown', 'quick', 'the']\n",
        "print(X.toarray())\n",
        "\n",
        "#noticed thatcat,dog,fox,lazy]>>>>>> not appeared becuse the numbers of repeats less than two"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvtC_M32FZjc",
        "outputId": "f5c84bdc-50c6-401d-feeb-33ca89b8a936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['brown' 'quick']\n",
            "[[0.70710678 0.70710678]\n",
            " [0.         0.        ]\n",
            " [0.70710678 0.70710678]]\n"
          ]
        }
      ],
      "source": [
        "cv = TfidfVectorizer(min_df=2,stop_words='english')\n",
        "X = cv.fit_transform([doc1, doc2, doc3])\n",
        "print(cv.get_feature_names_out())  # ['brown', 'quick', 'the']\n",
        "print(X.toarray())\n",
        "\n",
        "#noticed that [the]>>>>>>>>not appeared becuse it is from stop_word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgqSoNHyKjJs"
      },
      "source": [
        "##Another Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScLzGnNZIN7I",
        "outputId": "0b80a644-b5b2-4dac-8ae5-a117b7cd5eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['are' 'awesome' 'doing' 'hi' 'how' 'that' 'up' 'what' 'wow' 'you']\n",
            "[[0.54275734 0.         0.27137867 0.20639047 0.54275734 0.\n",
            "  0.         0.         0.         0.54275734]\n",
            " [0.         0.         0.         0.4736296  0.         0.\n",
            "  0.62276601 0.62276601 0.         0.        ]\n",
            " [0.         0.57735027 0.         0.         0.         0.57735027\n",
            "  0.         0.         0.57735027 0.        ]]\n"
          ]
        }
      ],
      "source": [
        "text=[\"Hi How are you How are you doing\",\"Hi what's up\",\"Wow that's awesome\"]\n",
        "cv = TfidfVectorizer(min_df=1)\n",
        "x_traincv = cv.fit_transform(text)\n",
        "feature_names = cv.get_feature_names_out()\n",
        "\n",
        "# Print the feature names and the TF-IDF matrix\n",
        "print(feature_names)\n",
        "print(x_traincv.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuzvrXTaKWOO",
        "outputId": "43287885-ce64-429c-fe94-297fd318d033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['awesome' 'doing' 'hi' 'wow']\n",
            "[[0.         0.79596054 0.60534851 0.        ]\n",
            " [0.         0.         1.         0.        ]\n",
            " [0.70710678 0.         0.         0.70710678]]\n"
          ]
        }
      ],
      "source": [
        "#Another Example\n",
        "\n",
        "text=[\"Hi How are you How are you doing\",\"Hi what's up\",\"Wow that's awesome\"]\n",
        "cv = TfidfVectorizer(min_df=1,stop_words='english')\n",
        "x_traincv = cv.fit_transform(text)\n",
        "feature_names = cv.get_feature_names_out()\n",
        "\n",
        "# Print the feature names and the TF-IDF matrix\n",
        "print(feature_names)\n",
        "print(x_traincv.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccr--90dzaHB"
      },
      "source": [
        "#Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyYwWTSZJH5W"
      },
      "source": [
        "### Word Embedding Techniques using Embedding Layer in Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al-PwLlTJH5Z"
      },
      "outputs": [],
      "source": [
        "### Libraries USed Tensorflow> 2.0  and keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNfAbxF_JH5a"
      },
      "outputs": [],
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rN8Qn9u-JH5a"
      },
      "outputs": [],
      "source": [
        "### sentences\n",
        "sents=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGmGq2G4JH5b",
        "outputId": "7965a4ea-387f-4b1d-af62-98686e3ab2a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEPuoylJqKTa"
      },
      "source": [
        "1-  In general, a larger vocabulary size allows for a more nuanced representation of the language, but it also increases the computational cost of training the embedding model. On the other hand, a smaller vocabulary size may limit the expressiveness of the embeddings and reduce the accuracy of the trained model.\n",
        "\n",
        "2- A reasonable starting point for a vocabulary size is around 20,000 to 30,000, but this may need to be adjusted up or down depending on your specific use case. If you have a smaller dataset or are working with a less complex language, you may be able to use a smaller vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxPwKSsfJH5c"
      },
      "outputs": [],
      "source": [
        "### Vocabulary size>>>> the size of unique words\n",
        "voc_size=10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baaVqWn4JH5c"
      },
      "source": [
        "#### One Hot Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc4ikAQiJH5c",
        "outputId": "7d5b2c38-d471-494b-9e89-ac8be83410cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2883, 7411, 3908, 6681], [2883, 7411, 3908, 6745], [2883, 8790, 3908, 8162], [3704, 3269, 5253, 4203, 8541], [3704, 3269, 5253, 4203, 6499], [5882, 2883, 1489, 3908, 6685], [6700, 2799, 5945, 4203]]\n"
          ]
        }
      ],
      "source": [
        "#will make one hot encoding and return each sentence with it's indices\n",
        "\n",
        "onehot_repr=[one_hot(sent,voc_size)for sent in sents]\n",
        "print(onehot_repr)\n",
        "\n",
        "\n",
        "#[2725, 4751, 1322, 7778] >>>>>the glass of milk(the numbers of indices of the words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtCaZYeTJH5d"
      },
      "source": [
        "### Word Embedding Represntation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-8SZmDnJH5d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55CUO8a1tQNJ"
      },
      "source": [
        "1- here, we will pass the result of one hot to embedding layer.\n",
        "\n",
        "2- but not all the sentences have same numbers of words , so i will make padding.\n",
        "\n",
        "3- padding='pre' or 'post'>>>> the zeros before or after indices to be same size.\n",
        "\n",
        "4- The choice of padding can affect the performance of the model, depending on the nature of the data. For example, if the end of the sequence is more important for the task at hand, you may want to use padding='pre' to preserve the order of the original sequence. On the other hand, if the beginning of the sequence is more important, you may want to use padding='post'. In some cases, it may be useful to try both options and see which one works better for your particular task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUBNvvjEJH5d",
        "outputId": "9c4a1bfc-1fc5-4312-8023-c8ad413fb3ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0 2883 7411 3908 6681]\n",
            " [   0    0    0    0 2883 7411 3908 6745]\n",
            " [   0    0    0    0 2883 8790 3908 8162]\n",
            " [   0    0    0 3704 3269 5253 4203 8541]\n",
            " [   0    0    0 3704 3269 5253 4203 6499]\n",
            " [   0    0    0 5882 2883 1489 3908 6685]\n",
            " [   0    0    0    0 6700 2799 5945 4203]]\n"
          ]
        }
      ],
      "source": [
        "sent_length=8\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)\n",
        "\n",
        "# sent_length >>> maximum numbers of words in sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJiH4HWJJH5e"
      },
      "outputs": [],
      "source": [
        "dim=10\n",
        "# dim >>> maximum numbers of vectors to represent one word in sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM2mOZAMJH5e"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzE_QuufJH5e",
        "outputId": "4a895f0f-eaf6-48eb-c126-48754e64a0b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 10)             100000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100000 (390.62 KB)\n",
            "Trainable params: 100000 (390.62 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePJNKiNwJH5e",
        "outputId": "aea2e532-0f88-44ea-f2b1-a350fa5f6a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 177ms/step\n",
            "[[[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.00665476  0.00694273  0.02852154  0.04741776  0.01549859\n",
            "   -0.03529092  0.03557928 -0.04992579 -0.00151428  0.03977767]\n",
            "  [-0.02445742 -0.01039945  0.04892126  0.04749333 -0.01364492\n",
            "   -0.02083243 -0.00756024  0.00465838  0.03740699 -0.0303151 ]\n",
            "  [ 0.02832193  0.00847127  0.00370447 -0.03426734 -0.03310901\n",
            "    0.00420745 -0.00620569  0.00268771 -0.04235294  0.03897474]\n",
            "  [ 0.04649255  0.00369128 -0.01723834 -0.00226138  0.00130426\n",
            "    0.00321114 -0.02550044 -0.0088807   0.04149229 -0.00471798]]\n",
            "\n",
            " [[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.00665476  0.00694273  0.02852154  0.04741776  0.01549859\n",
            "   -0.03529092  0.03557928 -0.04992579 -0.00151428  0.03977767]\n",
            "  [-0.02445742 -0.01039945  0.04892126  0.04749333 -0.01364492\n",
            "   -0.02083243 -0.00756024  0.00465838  0.03740699 -0.0303151 ]\n",
            "  [ 0.02832193  0.00847127  0.00370447 -0.03426734 -0.03310901\n",
            "    0.00420745 -0.00620569  0.00268771 -0.04235294  0.03897474]\n",
            "  [ 0.04068749 -0.02007303  0.02258701  0.02955471  0.04868075\n",
            "    0.03559405  0.00529225  0.02196762 -0.04631866 -0.01530103]]\n",
            "\n",
            " [[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.00665476  0.00694273  0.02852154  0.04741776  0.01549859\n",
            "   -0.03529092  0.03557928 -0.04992579 -0.00151428  0.03977767]\n",
            "  [-0.01777927  0.04868293  0.04214308 -0.00432346 -0.02333256\n",
            "   -0.00286937  0.01251594 -0.04506202 -0.04595719 -0.04285933]\n",
            "  [ 0.02832193  0.00847127  0.00370447 -0.03426734 -0.03310901\n",
            "    0.00420745 -0.00620569  0.00268771 -0.04235294  0.03897474]\n",
            "  [ 0.03970077 -0.01839745 -0.03829519  0.04135444  0.02697725\n",
            "    0.01229095 -0.045148    0.03983897 -0.01228712 -0.01050899]]\n",
            "\n",
            " [[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.04268544 -0.03006657  0.03547206 -0.00283514 -0.03395072\n",
            "   -0.02646589  0.03225506 -0.04978156  0.02358783  0.03872504]\n",
            "  [-0.03338172 -0.04911062  0.01145379  0.01380255  0.02513162\n",
            "   -0.01542987  0.03751483 -0.02404425 -0.03469671 -0.02841014]\n",
            "  [ 0.02879334 -0.03998922  0.04984942 -0.04839226 -0.015839\n",
            "    0.04697667 -0.0069112  -0.0146118  -0.0428631  -0.01636677]\n",
            "  [-0.01218277 -0.04967988 -0.0159957  -0.02743992 -0.00940899\n",
            "   -0.04149666  0.04782403 -0.01362912 -0.04514324  0.03711339]\n",
            "  [ 0.0359262   0.04461206 -0.0028706   0.04651639 -0.04164107\n",
            "    0.04528617  0.01871928  0.02619821 -0.02394482  0.00605426]]\n",
            "\n",
            " [[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.04268544 -0.03006657  0.03547206 -0.00283514 -0.03395072\n",
            "   -0.02646589  0.03225506 -0.04978156  0.02358783  0.03872504]\n",
            "  [-0.03338172 -0.04911062  0.01145379  0.01380255  0.02513162\n",
            "   -0.01542987  0.03751483 -0.02404425 -0.03469671 -0.02841014]\n",
            "  [ 0.02879334 -0.03998922  0.04984942 -0.04839226 -0.015839\n",
            "    0.04697667 -0.0069112  -0.0146118  -0.0428631  -0.01636677]\n",
            "  [-0.01218277 -0.04967988 -0.0159957  -0.02743992 -0.00940899\n",
            "   -0.04149666  0.04782403 -0.01362912 -0.04514324  0.03711339]\n",
            "  [-0.00544126 -0.00374953 -0.04672927  0.00924076 -0.01178169\n",
            "    0.01010606  0.00372535 -0.03769083  0.01511868 -0.04306487]]\n",
            "\n",
            " [[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [ 0.01384897  0.01281137 -0.03297792 -0.04283642  0.01882318\n",
            "   -0.04672382  0.03456997 -0.03954574 -0.04709084 -0.03734943]\n",
            "  [-0.00665476  0.00694273  0.02852154  0.04741776  0.01549859\n",
            "   -0.03529092  0.03557928 -0.04992579 -0.00151428  0.03977767]\n",
            "  [-0.0276739  -0.03982071 -0.04881737  0.03739643  0.00571982\n",
            "    0.04233743  0.02400217 -0.01821949 -0.03735027  0.00497448]\n",
            "  [ 0.02832193  0.00847127  0.00370447 -0.03426734 -0.03310901\n",
            "    0.00420745 -0.00620569  0.00268771 -0.04235294  0.03897474]\n",
            "  [ 0.02883748  0.04057897 -0.04117857 -0.00178703 -0.00374297\n",
            "    0.00150201  0.03061627 -0.04989552  0.03752731  0.04602799]]\n",
            "\n",
            " [[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563\n",
            "    0.02848453 -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            "  [ 0.00304999  0.03097751  0.02598338  0.0497039  -0.03236001\n",
            "   -0.04961625  0.03157211 -0.03854791  0.00799966  0.01217837]\n",
            "  [ 0.01019224  0.04620394  0.00154772  0.01893653 -0.04054292\n",
            "   -0.00565128  0.00113317 -0.03143074 -0.01008171 -0.03195762]\n",
            "  [-0.00779357 -0.02454161  0.01173782 -0.02476003 -0.00166791\n",
            "   -0.02227789 -0.00759176  0.00437319 -0.04216974  0.02361492]\n",
            "  [-0.01218277 -0.04967988 -0.0159957  -0.02743992 -0.00940899\n",
            "   -0.04149666  0.04782403 -0.01362912 -0.04514324  0.03711339]]]\n"
          ]
        }
      ],
      "source": [
        "print(model.predict(embedded_docs))\n",
        "#there are the features would be used in the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sraokIRpJH5f",
        "outputId": "9bf3093d-ac23-42eb-90c1-7ee9ed614e71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 2883, 7411, 3908, 6681], dtype=int32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#frist sentence after onehot + padding\n",
        "embedded_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9waC6dFJH5f",
        "outputId": "f4a853ec-e493-454d-acf4-195bd92015ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "[[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563  0.02848453\n",
            "  -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            " [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563  0.02848453\n",
            "  -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            " [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563  0.02848453\n",
            "  -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            " [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563  0.02848453\n",
            "  -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            " [-0.00665476  0.00694273  0.02852154  0.04741776  0.01549859 -0.03529092\n",
            "   0.03557928 -0.04992579 -0.00151428  0.03977767]\n",
            " [-0.02445742 -0.01039945  0.04892126  0.04749333 -0.01364492 -0.02083243\n",
            "  -0.00756024  0.00465838  0.03740699 -0.0303151 ]\n",
            " [ 0.02832193  0.00847127  0.00370447 -0.03426734 -0.03310901  0.00420745\n",
            "  -0.00620569  0.00268771 -0.04235294  0.03897474]\n",
            " [ 0.04649255  0.00369128 -0.01723834 -0.00226138  0.00130426  0.00321114\n",
            "  -0.02550044 -0.0088807   0.04149229 -0.00471798]]\n"
          ]
        }
      ],
      "source": [
        "#frist sentence after embedding\n",
        "print(model.predict(embedded_docs)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqlU6dM1JH5f",
        "outputId": "e6aeea7f-35a3-4ff2-d4d4-08a38b622f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563  0.02848453\n",
            "  -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            " [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563  0.02848453\n",
            "  -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            " [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563  0.02848453\n",
            "  -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            " [-0.01999989  0.04437989  0.02153428 -0.025058    0.02389563  0.02848453\n",
            "  -0.04522064 -0.0022557  -0.01827334 -0.02757515]\n",
            " [-0.00665476  0.00694273  0.02852154  0.04741776  0.01549859 -0.03529092\n",
            "   0.03557928 -0.04992579 -0.00151428  0.03977767]\n",
            " [-0.02445742 -0.01039945  0.04892126  0.04749333 -0.01364492 -0.02083243\n",
            "  -0.00756024  0.00465838  0.03740699 -0.0303151 ]\n",
            " [ 0.02832193  0.00847127  0.00370447 -0.03426734 -0.03310901  0.00420745\n",
            "  -0.00620569  0.00268771 -0.04235294  0.03897474]\n",
            " [ 0.04068749 -0.02007303  0.02258701  0.02955471  0.04868075  0.03559405\n",
            "   0.00529225  0.02196762 -0.04631866 -0.01530103]]\n"
          ]
        }
      ],
      "source": [
        "print(model.predict(embedded_docs)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqv5eZEwvtsy"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "\n",
        "# Tokenize the sentences into words\n",
        "tokenized_sents = [nltk.word_tokenize(sent) for sent in sents]\n",
        "\n",
        "# Create the Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=tokenized_sents, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Train the model\n",
        "word2vec_model.train(tokenized_sents, total_examples=len(tokenized_sents), epochs=10)\n",
        "\n",
        "# Get the vector for a specific word\n",
        "word_vector = word2vec_model.wv['glass']\n",
        "print(word_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LkorJe9vtsy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDbDAHMjKg6n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CtJ2nVPqluq2",
        "JlNxwU4emHQs",
        "v2G9S9SamtU5",
        "CTDrLBHjpn8s",
        "wbMYT37ht1d7",
        "p5RAWJj_9wQh",
        "Jx9X26LW-yuy",
        "IT478mmsw6nI",
        "UUrhx_p53hrK",
        "YnzqQ88W4SI_",
        "2xKEtJzaN3RQ",
        "hBgOLzIrSH5O",
        "iMCQUGPRSsZG",
        "bu6v1JbMS_12",
        "RjGt0FRfi8w1",
        "oFec2wMNoy16",
        "lXZ3x4YB1mTP",
        "mdGK-oL2bS5B",
        "YxU5AJljkEis",
        "fja1Hz8xkLCf",
        "iT_sLD4lkvTY",
        "tbmAW3Mo2LDh"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}